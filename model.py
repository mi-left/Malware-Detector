import numpy as np
from sklearn.feature_extraction import FeatureHasher
import glob
from sklearn.model_selection import train_test_split
from tensorflow import keras
from keras import layers
from keras import regularizers




def extract_features(file_paths: list[str]) -> np.ndarray:

    features = []
    for file_path in file_paths:
        #cp = subprocess.run(["strings", file_path], capture_output=True)  #reads in the string 
        #cp = cp.stdout.decode('utf-8') #changes into readable format
        #array= cp.split("\n") #splits newline
        with open(file_path, "rb") as file:
            array = file.read()

        #ngrams = []
        

        ngram_freq = {}
        for i in range(len(array) - window_size + 1):
            ngram = array[i:i+window_size]
            if ngram in ngram_freq:
                ngram_freq[ngram] += 1
            else:
                ngram_freq[ngram] = 1
            #ngrams.append(str(ngram))
        #new_array = [[i] for i in ngrams]
        #print(new_array)
        features.append(ngram_freq)

    h = FeatureHasher(n_features=feature_num, input_type= "string")
    f = h.transform(features)#.astype(np.int64)

    #print(f.toarray())
    #features.append(f.toarray())
    return f.toarray()



#HYPERPARAMETERS
#Need to run new features
feature_num = 25000
window_size = 3 
split = 0.2
seed = 4269
#Can use saved features
hidden_size = 512
hidden_size2 = hidden_size * 2
batch_size = 128
epochs = 10
dropout_rate = 0.5
regularizer_factor=0.001
val_split = 0.1


new_features=False
benign_folder_path = "../train/benignware"
malware_folder_path = "../train/malware"


benign_file_paths = glob.glob(benign_folder_path + "/*")
malware_file_paths = glob.glob(malware_folder_path + "/*") #gets all the files within that directory



def main():
    #Split the data into training and testing sets
    benign_train, benign_test = train_test_split(benign_file_paths, test_size=split, random_state=seed) # seed for reproducible results
    mal_train, mal_test = train_test_split(malware_file_paths, test_size=split, random_state=seed) # seed for reproducible results

    if new_features:
        benign_features_train = extract_features(benign_train)
        benign_features_test = extract_features(benign_test)
        print("benign features done")
        with open('benign_features_train.npy', 'wb') as f:
            np.save(f, benign_features_train)
        with open('benign_features_test.npy', 'wb') as f:
            np.save(f, benign_features_test)

        mal_features_train = extract_features(mal_train)
        mal_features_test = extract_features(mal_test)
        print("malwaer features done")
        with open('mal_features_train.npy', 'wb') as f:
            np.save(f, mal_features_train)
        with open('mal_features_test.npy', 'wb') as f:
            np.save(f, mal_features_test)
    else:
        with open('benign_features_train.npy', 'rb') as f:
            benign_features_train = np.load(f)
        with open('benign_features_test.npy', 'rb') as f:
            benign_features_test = np.load(f)

        with open('mal_features_train.npy', 'rb') as f:
            mal_features_train = np.load(f)
        with open('mal_features_test.npy', 'rb') as f:
            mal_features_test = np.load(f)

    # Prepare labels
    benign_labels_train = np.zeros(len(benign_features_train))
    benign_labels_test = np.zeros(len(benign_features_test))

    mal_labels_train = np.ones(len(mal_features_train))
    mal_labels_test = np.ones(len(mal_features_test))

    # Combine features and labels

    features_train = np.vstack((benign_features_train, mal_features_train))
    labels_train = np.hstack((benign_labels_train, mal_labels_train))
    features_test = np.vstack((benign_features_test, mal_features_test))
    labels_test = np.hstack((benign_labels_test, mal_labels_test))

    #shuffle data
    shuffled_indices = np.random.permutation(features_train.shape[0])
    features_train = features_train[shuffled_indices]
    labels_train = labels_train[shuffled_indices]

    shuffled_indices = np.random.permutation(features_test.shape[0])
    features_test = features_test[shuffled_indices]
    labels_test = labels_test[shuffled_indices]



    # convert class vectors to binary class matrices
    #y_train = keras.utils.to_categorical(train, num_classes)
    #y_test = keras.utils.to_categorical(train_test, num_classes)

    model = keras.Sequential(
        [
            keras.Input(shape=(feature_num,)),
            layers.Dense(hidden_size, kernel_regularizer=regularizers.l2(regularizer_factor), activation="relu"),
            layers.Dropout(dropout_rate),
            layers.Dense(hidden_size2, kernel_regularizer=regularizers.l2(regularizer_factor), activation="relu"),
            layers.Dropout(dropout_rate),
            layers.Dense(hidden_size2, kernel_regularizer=regularizers.l2(regularizer_factor), activation="relu"),
            layers.Dropout(dropout_rate),
            layers.Dense(hidden_size, kernel_regularizer=regularizers.l2(regularizer_factor), activation="relu"),
            layers.Dropout(dropout_rate),

            layers.Dense(1, activation="sigmoid"),
        ]
    )

    model.summary()

    model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

    model.fit(features_train, labels_train, batch_size=batch_size, epochs=epochs, validation_split=val_split)

    score = model.evaluate(features_test, labels_test, verbose=0)
    print("Test loss:", score[0])
    print("Test accuracy:", score[1])

    model.save("detection_model")



if __name__ == "__main__":
    main()
